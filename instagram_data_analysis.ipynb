{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hozJu7Q5Ews1"
      },
      "source": [
        "# Project 1\n",
        "\n",
        "Data Source: https://rapidapi.com/mrngstar/api/instagram-scraper-api3\n",
        "\n",
        "Instagram: @marcitocastro (482001976) - https://www.instagram.com/marcitocastro/\n",
        "\n",
        "- Profile Data (twice)\n",
        "- General Information About the Last 24 Posts (twice)\n",
        "- Comments from the Last Post (twice)\n",
        "- Classification of Comments from the Last Post (twice)\n",
        "  - Data and Time of Data Extraction:\n",
        "    - 2024-09-18 / 05:03:20.26\n",
        "    - 2024-09-21 / 19:04:30.89"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Er9LaE9GE-qo"
      },
      "source": [
        "## Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtiO-lloGcF1"
      },
      "outputs": [],
      "source": [
        "!pip install requests\n",
        "!apt-get update # Update apt-get repository.\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null # Install Java.\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz # Download Apache Spark.\n",
        "!tar xf spark-3.1.1-bin-hadoop3.2.tgz # Unzip the tgz file.\n",
        "!pip install pyspark==3.1.1\n",
        "!pip install -q findspark # Install findspark. Adds PySpark to the System path during runtime.\n",
        "!pip install -U google-generativeai # Install or update the Google Generative AI package.\n",
        "!ls\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kBRksOqFL8B"
      },
      "source": [
        "## Configure Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "bA3N5KXqGjQJ",
        "outputId": "f6b42d9d-77fb-44c4-d1b9-7cd3d68ae113"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://4dd7f0baba07:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Instagram Data Analysis</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f66548e5240>"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Import libraries\n",
        "import requests\n",
        "import json\n",
        "import findspark\n",
        "import os\n",
        "import pandas as pd\n",
        "import pyspark\n",
        "from pyspark.sql import DataFrame, SparkSession\n",
        "from typing import List, Tuple, Dict\n",
        "from array import ArrayType\n",
        "import pyspark.sql.types as T\n",
        "import pyspark.sql.functions as F\n",
        "import google.generativeai as genai # Import the Google Generative AI module\n",
        "from google.colab import userdata\n",
        "from google.colab import drive\n",
        "\n",
        "# Configure environment variables\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\"\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Initialize Spark session\n",
        "findspark.init()\n",
        "spark = SparkSession.builder.appName(\"Instagram Data Analysis\").getOrCreate()\n",
        "spark\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmZAej3BFLon"
      },
      "source": [
        "## Get Infos from Instagram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtqz-SDwFLhs"
      },
      "source": [
        "### Get PROFILE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KEDL_QSuHU9l"
      },
      "outputs": [],
      "source": [
        "def get_influencer_profile(influencer: str, url: str, headers: dict):\n",
        "    \"\"\"\n",
        "    Fetches the profile information of the given Instagram influencer.\n",
        "\n",
        "    Args:\n",
        "        influencer (str): The username of the Instagram influencer.\n",
        "        url (str): The base URL for the Instagram API.\n",
        "        headers (dict): Headers required for the API request.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        querystring = {\"username_or_id\": influencer}\n",
        "        method = 'user_info'\n",
        "        response = requests.get(f'{url}{method}', headers=headers, params=querystring)\n",
        "        response.raise_for_status() # Checks if there was an HTTP error\n",
        "\n",
        "        response_instagram = response.json()\n",
        "\n",
        "        profile = response_instagram.get(\"data\", {})\n",
        "\n",
        "        full_name = profile.get('full_name')\n",
        "        profile_id  = profile.get('id')\n",
        "        biography = profile.get('biography')\n",
        "        category = profile.get('category')\n",
        "        bio_links = profile.get('bio_links')\n",
        "        follower_count = profile.get('follower_count')\n",
        "        following_count = profile.get('following_count')\n",
        "\n",
        "        hd_profile_pic_versions = profile.get('hd_profile_pic_versions', [])\n",
        "        hd_profile_pic_versions_url = hd_profile_pic_versions[0].get('url') if hd_profile_pic_versions else None\n",
        "\n",
        "        media_count = profile.get('media_count')\n",
        "        is_verified = profile.get('is_verified')\n",
        "        threads_profile_glyph_url = profile.get('threads_profile_glyph_url')\n",
        "\n",
        "        data_profile = [(\n",
        "            full_name, profile_id, biography, category, bio_links, follower_count, following_count, hd_profile_pic_versions_url,\n",
        "            media_count, is_verified, threads_profile_glyph_url\n",
        "        )]\n",
        "\n",
        "        return data_profile\n",
        "\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"Error fetching influencer profile: {e}\")\n",
        "        return []\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMop5gT0FLbc"
      },
      "source": [
        "### Get POSTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEbT2BTdHZi6"
      },
      "outputs": [],
      "source": [
        "def get_influencer_posts(influencer: str, url: str, headers: dict):\n",
        "    \"\"\"\n",
        "    Fetches up to 24 posts of the given Instagram influencer\n",
        "\n",
        "    Args:\n",
        "        influencer (str): The username of the Instagram influencer.\n",
        "        url (str): The base URL for the Instagram API.\n",
        "        headers (dict): Headers required for the API request.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        method = 'user_posts'\n",
        "        latest_post_code = ''\n",
        "        next_max_id = None\n",
        "        data_posts = []\n",
        "\n",
        "        for i in range(2):  # Limit to two requests\n",
        "            querystring = {\"username_or_id\": influencer, \"count\": \"12\"}\n",
        "\n",
        "            if next_max_id:\n",
        "                querystring[\"max_id\"] = next_max_id\n",
        "\n",
        "            response = requests.get(f'{url}{method}', headers=headers, params=querystring)\n",
        "            response.raise_for_status() # Checks if there was an HTTP error\n",
        "\n",
        "            response_instagram = response.json()\n",
        "\n",
        "            items = response_instagram.get('data', {}).get('items', [])\n",
        "            next_max_id = response_instagram.get('data', {}).get('next_max_id')\n",
        "\n",
        "            # Process each post\n",
        "            for item in items:\n",
        "                post_id = item.get('id')\n",
        "                code = item.get('code')\n",
        "\n",
        "                # Update the latest post code if not pinned\n",
        "                if item.get('timeline_pinned_user_ids') == None:\n",
        "                    if latest_post_code == '':\n",
        "                        latest_post_code = code\n",
        "\n",
        "                device_timestamp = item.get('device_timestamp')\n",
        "                like_and_view_counts_disabled = item.get('like_and_view_counts_disabled')\n",
        "                caption = item.get('caption')\n",
        "                image_versions2 = item.get('image_versions2')\n",
        "                product_type = item.get('product_type')\n",
        "                coauthor_producers = item.get('coauthor_producers')\n",
        "                like_count = item.get('like_count')\n",
        "                comment_count = item.get('comment_count')\n",
        "                reshare_count = item.get('reshare_count')\n",
        "                timeline_pinned_user_ids = item.get('timeline_pinned_user_ids')\n",
        "\n",
        "                data_posts.append((\n",
        "                    post_id, code, device_timestamp, like_and_view_counts_disabled, caption, image_versions2, product_type,\n",
        "                    coauthor_producers, like_count, comment_count, reshare_count, timeline_pinned_user_ids\n",
        "                ))\n",
        "\n",
        "            if not next_max_id:\n",
        "                break\n",
        "\n",
        "        return data_posts, latest_post_code\n",
        "\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"Error fetching influencer posts: {e}\")\n",
        "        return [], None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVfGvpEtFLM9"
      },
      "source": [
        "### Get COMMENTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ky_dl6KuHdX2"
      },
      "outputs": [],
      "source": [
        "def get_comments_for_latest_post(latest_post_code: str, url: str, headers: dict):\n",
        "    \"\"\"\n",
        "    Fetches comments for the latest post of the given Instagram influencer.\n",
        "\n",
        "    Args:\n",
        "        latest_post_code (str): The code of the latest post.\n",
        "        url (str): The base URL for the Instagram API.\n",
        "        headers (dict): Headers required for the API request.\n",
        "    \"\"\"\n",
        "    method = 'media_comments'\n",
        "    min_id = None\n",
        "    data_comments = []\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            querystring = {\"code_or_id_or_url\": latest_post_code, \"sort_order\": \"recent\", \"min_id\": min_id}\n",
        "            response = requests.get(f'{url}{method}', headers=headers, params=querystring)\n",
        "            response.raise_for_status() # Checks if there was an HTTP error\n",
        "\n",
        "            response_instagram = response.json()\n",
        "            array_comments = response_instagram.get('data', {}).get('comments', [])\n",
        "\n",
        "            # Loop through each comment in the response and extract relevant details\n",
        "            for comment in array_comments:\n",
        "                pk = comment.get('pk')\n",
        "                user_id = comment.get('user_id')\n",
        "                text = comment.get('text')\n",
        "                comment_like_count = comment.get('comment_like_count', 0)\n",
        "                child_comment_count = comment.get('child_comment_count', 0)\n",
        "                user_username = comment.get('user', {}).get('username')\n",
        "                user_full_name = comment.get('user', {}).get('full_name')\n",
        "                user_is_verified = comment.get('user', {}).get('is_verified')\n",
        "\n",
        "                # Store each comment's data in a dictionary\n",
        "                data_comments.append((\n",
        "                    pk, user_id, text, comment_like_count, child_comment_count, user_username, user_full_name, user_is_verified\n",
        "                ))\n",
        "\n",
        "            # Check if there is a next page of comments\n",
        "            min_id = response_instagram.get('data', {}).get('next_min_id')\n",
        "            if not min_id:\n",
        "                break\n",
        "\n",
        "        except requests.RequestException as e:\n",
        "            print(f\"Error fetching comments: {e}\")\n",
        "            break\n",
        "\n",
        "    return data_comments\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtYaHHx3HxHU"
      },
      "source": [
        "## Main Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YisY_NmJHz7j"
      },
      "outputs": [],
      "source": [
        "def main(influencer: str, url: str, headers: dict):\n",
        "    \"\"\"\n",
        "    Main function to run the workflow: fetching profile, posts, comments for the latest post and saving to Data Lake.\n",
        "\n",
        "    Args:\n",
        "        influencer (str): The username of the Instagram influencer.\n",
        "        url (str): The base URL for the Instagram API.\n",
        "        headers (dict): Headers required for the API request.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Get influencer profile\n",
        "        data_profile = get_influencer_profile(influencer, url, headers)\n",
        "        if not data_profile:\n",
        "            raise ValueError(\"Profile data could not be retrieved\")\n",
        "        else:\n",
        "            # Create and save DataFrame for profile\n",
        "            schema_profile = T.StructType([\n",
        "                T.StructField(\"full_name\", T.StringType(), nullable=False),\n",
        "                T.StructField(\"id\", T.StringType(), nullable=True),\n",
        "                T.StructField(\"biography\", T.StringType(), nullable=True),\n",
        "                T.StructField(\"category\", T.StringType(), nullable=True),\n",
        "                T.StructField(\"bio_links\", T.StringType(), nullable=True),\n",
        "                T.StructField(\"follower_count\", T.StringType(), nullable=True),\n",
        "                T.StructField(\"following_count\", T.StringType(), nullable=True),\n",
        "                T.StructField(\"hd_profile_pic_versions_url\", T.StringType(), nullable=True),\n",
        "                T.StructField(\"media_count\", T.StringType(), nullable=True),\n",
        "                T.StructField(\"is_verified\", T.StringType(), nullable=True),\n",
        "                T.StructField(\"threads_profile_glyph_url\", T.StringType(), nullable=True)\n",
        "            ])\n",
        "\n",
        "            df_profile = spark.createDataFrame(data_profile, schema=schema_profile)\n",
        "            df_profile = df_profile.withColumn('ts_exec', F.current_timestamp())\n",
        "            df_profile.write.partitionBy(\"full_name\", \"ts_exec\").mode(\"append\").format('parquet').save('/content/drive/MyDrive/Datalake/Instagram/Profile/')\n",
        "\n",
        "        # Get posts\n",
        "        data_posts, latest_post_code = get_influencer_posts(influencer, url, headers)\n",
        "        if not data_posts or not latest_post_code:\n",
        "            raise ValueError(\"Post data or latest post code could not be retrieved\")\n",
        "        else:\n",
        "            # Create and save DataFrame for posts\n",
        "            schema_posts = T.StructType([\n",
        "                T.StructField(\"id\", T.StringType(), nullable=True),\n",
        "                T.StructField(\"code\", T.StringType(), nullable=True),\n",
        "                T.StructField(\"device_timestamp\", T.StringType(), nullable=True),\n",
        "                T.StructField(\"like_and_view_counts_disabled\", T.StringType(), nullable=True),\n",
        "                T.StructField(\"caption\", T.StringType(), nullable=True),\n",
        "                T.StructField(\"image_versions2\", T.StringType(), nullable=True),\n",
        "                T.StructField(\"product_type\", T.StringType(), nullable=True),\n",
        "                T.StructField(\"coauthor_producers\", T.StringType(), nullable=True),\n",
        "                T.StructField(\"like_count\", T.StringType(), nullable=True),\n",
        "                T.StructField(\"comment_count\", T.StringType(), nullable=True),\n",
        "                T.StructField(\"reshare_count\", T.StringType(), nullable=True),\n",
        "                T.StructField(\"timeline_pinned_user_ids\", T.StringType(), nullable=True)\n",
        "            ])\n",
        "\n",
        "            df_posts = spark.createDataFrame(data_posts, schema=schema_posts)\n",
        "            df_posts = df_posts.withColumn('ts_exec', F.current_timestamp())\n",
        "            df_posts.write.partitionBy(\"ts_exec\").mode(\"append\").format('parquet').save('/content/drive/MyDrive/Datalake/Instagram/Posts/')\n",
        "\n",
        "        # Get comments for the latest post\n",
        "        comments_data = get_comments_for_latest_post(latest_post_code, url, headers)\n",
        "        if comments_data:\n",
        "            # Create and save DataFrame for comments\n",
        "            schema_comments = T.StructType([\n",
        "                T.StructField(\"pk\", T.StringType(), nullable=True),\n",
        "                T.StructField(\"user_id\", T.StringType(), nullable=True),\n",
        "                T.StructField(\"text\", T.StringType(), nullable=True),\n",
        "                T.StructField(\"comment_like_count\", T.StringType(), nullable=True),\n",
        "                T.StructField(\"child_comment_count\", T.StringType(), nullable=True),\n",
        "                T.StructField(\"user_username\", T.StringType(), nullable=True),\n",
        "                T.StructField(\"user_full_name\", T.StringType(), nullable=True),\n",
        "                T.StructField(\"user_is_verified\", T.StringType(), nullable=True)\n",
        "            ])\n",
        "\n",
        "            df_comments = spark.createDataFrame(comments_data, schema=schema_comments)\n",
        "            df_comments = df_comments.withColumn('ts_exec', F.current_timestamp())\n",
        "            df_comments.write.partitionBy(\"ts_exec\").mode(\"append\").format('parquet').save('/content/drive/MyDrive/Datalake/Instagram/Comments/')\n",
        "        else:\n",
        "            print(\"No comments found for the latest post\")\n",
        "\n",
        "    except ValueError as e:\n",
        "        print(f\"Error in the main workflow: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Unexpected error: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLWy-LGrc781"
      },
      "source": [
        "## Classify Comments Using Google Gemini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72paq15WdIHM"
      },
      "outputs": [],
      "source": [
        "def classify_comment(text: str, gemini_api_key: str):\n",
        "    \"\"\"\n",
        "    Classifies the sentiment of a comment using the Google Gemini API.\n",
        "\n",
        "    Args:\n",
        "        text (str): The comment text to classify.\n",
        "        gemini_api_key (str): The API key for Google Gemini.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        genai.configure(api_key=gemini_api_key)\n",
        "        model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "        prompt = f'Classify the following comment as (Positive, Negative, Neutral, Humorous). Return only the classification: {text}'\n",
        "        response = model.generate_content(prompt)\n",
        "\n",
        "        return response.text.strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error classifying comment: {e}\")\n",
        "\n",
        "        return 'Unknown'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8s1XhQqGdH62"
      },
      "outputs": [],
      "source": [
        "def classify_comments_for_the_latest_post(influencer: str, url: str, headers: dict, gemini_api_key: str):\n",
        "    \"\"\"\n",
        "    Classifies the sentiment of comments on the latest Instagram post and stores the results in a Data Lake.\n",
        "\n",
        "    Args:\n",
        "        influencer (str): The username of the Instagram influencer.\n",
        "        url (str): The base URL for the Instagram API.\n",
        "        headers (dict): Headers required for the API request.\n",
        "        gemini_api_key (str): The API key for Google Gemini.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Get comments for the latest post\n",
        "        data_posts, latest_post_code = get_influencer_posts(influencer, url, headers)\n",
        "        comments_data = get_comments_for_latest_post(latest_post_code, url, headers)\n",
        "        if comments_data:\n",
        "            # Classify comments using Google Gemini\n",
        "            comments_to_classify = comments_data[:20]  # Limit to 20 comments\n",
        "\n",
        "            classified_comments = [(pk, text, classify_comment(text, gemini_api_key))\n",
        "                                  for (pk, user_id, text, comment_like_count, child_comment_count, user_username, user_full_name, user_is_verified)\n",
        "                                  in comments_to_classify]\n",
        "\n",
        "            # Create and save DataFrame for classified comments\n",
        "            schema_classified_comments = T.StructType([\n",
        "                T.StructField(\"pk\", T.StringType(), nullable=True),\n",
        "                T.StructField(\"text_original\", T.StringType(), nullable=True),\n",
        "                T.StructField(\"classification\", T.StringType(), nullable=True)\n",
        "            ])\n",
        "\n",
        "            df_classified_comments = spark.createDataFrame(classified_comments, schema=schema_classified_comments)\n",
        "            df_classified_comments = df_classified_comments.withColumn('ts_exec', F.current_timestamp())\n",
        "            df_classified_comments.write.partitionBy(\"ts_exec\").mode(\"append\").format('parquet').save('/content/drive/MyDrive/Datalake/Instagram/Classified_comments/')\n",
        "        else:\n",
        "            print(\"No comments found for the latest post\")\n",
        "\n",
        "    except ValueError as e:\n",
        "        print(f\"Error in the main workflow: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Unexpected error: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbFacw_8dcBB"
      },
      "source": [
        "## Define the Parameters and Execute the Workflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ClFMEch0dbSP"
      },
      "outputs": [],
      "source": [
        "# Define your parameters\n",
        "influencer = 'marcitocastro'\n",
        "\n",
        "url = 'https://instagram-scraper-api3.p.rapidapi.com/'\n",
        "\n",
        "headers = {\n",
        "    'x-rapidapi-key': userdata.get('x-rapidapi-key'),\n",
        "    'x-rapidapi-host': 'instagram-scraper-api3.p.rapidapi.com'\n",
        "}\n",
        "\n",
        "gemini_api_key = userdata.get('gemini_api_key')\n",
        "\n",
        "# Execute the workflow\n",
        "main(influencer, url, headers)\n",
        "classify_comments_for_the_latest_post(influencer, url, headers, gemini_api_key)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLEcUf_QurLz"
      },
      "source": [
        "## Analytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMvxtUCuZgm5",
        "outputId": "a22a5d6a-ecd4-4ce5-9b08-12614e9bf520"
      },
      "outputs": [],
      "source": [
        "df_profile = spark.read.parquet('/content/drive/MyDrive/Datalake/Instagram/Profile/')\n",
        "\n",
        "df_profile.createOrReplaceTempView(\"df_profile\")\n",
        "\n",
        "spark.sql(\"\"\"\n",
        "SELECT *\n",
        "FROM df_profile\n",
        "\"\"\"\n",
        ").show(truncate=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtjiNOqAZAnI",
        "outputId": "de204e03-6a86-44ca-edc1-e9f40c649905"
      },
      "outputs": [],
      "source": [
        "df_posts = spark.read.parquet('/content/drive/MyDrive/Datalake/Instagram/Posts/')\n",
        "\n",
        "df_posts.createOrReplaceTempView(\"df_posts\")\n",
        "\n",
        "spark.sql(\"\"\"\n",
        "SELECT *\n",
        "FROM df_posts\n",
        "\"\"\"\n",
        ").show(10, truncate=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-Y186ZIseC6",
        "outputId": "20044f1c-4136-41c3-9f0c-5d1b84756ece"
      },
      "outputs": [],
      "source": [
        "df_comments = spark.read.parquet('/content/drive/MyDrive/Datalake/Instagram/Comments/')\n",
        "\n",
        "df_comments.createOrReplaceTempView(\"df_comments\")\n",
        "\n",
        "spark.sql(\"\"\"\n",
        "SELECT *\n",
        "FROM df_comments\n",
        "\"\"\"\n",
        ").show(10, truncate=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHcBY5oMt8Hf",
        "outputId": "2d81f7a0-c706-4d01-927e-a959522a2f7f"
      },
      "outputs": [],
      "source": [
        "df_classified_comments = spark.read.parquet('/content/drive/MyDrive/Datalake/Instagram/Classified_comments/')\n",
        "\n",
        "df_classified_comments.createOrReplaceTempView(\"df_classified_comments\")\n",
        "\n",
        "spark.sql(\"\"\"\n",
        "SELECT *\n",
        "FROM df_classified_comments\n",
        "\"\"\"\n",
        ").show(10, truncate=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlrzwJNgysaf",
        "outputId": "69e0c482-37a9-4112-8558-3855fab5ef7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------+-----------------------+\n",
            "|follower_count|ts_exec                |\n",
            "+--------------+-----------------------+\n",
            "|822214        |2024-09-21 19:04:30.894|\n",
            "|820374        |2024-09-18 05:03:20.26 |\n",
            "+--------------+-----------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 1. Influencer's Number of Followers\n",
        "followers_count_query = \"\"\"\n",
        "SELECT\n",
        "    follower_count,\n",
        "    ts_exec\n",
        "FROM df_profile\n",
        "ORDER BY ts_exec DESC\n",
        "\"\"\"\n",
        "followers_count = spark.sql(followers_count_query)\n",
        "followers_count.show(truncate=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ruzb1OXzcHk",
        "outputId": "704fedb6-a875-4704-b8b3-6a2a411a84e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------------+---------------+---------------------------+-----------------+\n",
            "|qnt_posts_analyzed|total_followers|sum_likes_comments_reshares|  engagement_rate|\n",
            "+------------------+---------------+---------------------------+-----------------+\n",
            "|                48|         822214|                   888473.0|2.251220991939649|\n",
            "+------------------+---------------+---------------------------+-----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 2. Engagement Rate (AVG per Post) - (Sum of Interactions across Multiple Posts / (Number of Posts * Number of Followers)) * 100\n",
        "engagement_rate_query = \"\"\"\n",
        "SELECT\n",
        "    COUNT(post.id) AS qnt_posts_analyzed,\n",
        "    prof.follower_count AS total_followers,\n",
        "    SUM(post.like_count + post.comment_count + post.reshare_count) AS sum_likes_comments_reshares,\n",
        "    (SUM(post.like_count + post.comment_count + post.reshare_count) / (COUNT(post.id) * prof.follower_count)) * 100 AS engagement_rate\n",
        "FROM df_posts post\n",
        "CROSS JOIN df_profile prof\n",
        "WHERE prof.ts_exec = (SELECT MAX(ts_exec) FROM df_profile) -- Último número de seguidores registrado\n",
        "GROUP BY prof.follower_count\n",
        "\"\"\"\n",
        "engagement_rate = spark.sql(engagement_rate_query)\n",
        "engagement_rate.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeLC8GFHFN8a",
        "outputId": "659a82cf-fc1f-4d3e-b389-7d725be06676"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------------+-----------+------------------+\n",
            "|qnt_posts_analyzed|total_likes|         avg_likes|\n",
            "+------------------+-----------+------------------+\n",
            "|                48|   584287.0|12172.645833333334|\n",
            "+------------------+-----------+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 3. AVG Likes per Post\n",
        "avg_likes_query = \"\"\"\n",
        "SELECT\n",
        "    COUNT(post.id) AS qnt_posts_analyzed,\n",
        "    SUM(post.like_count) AS total_likes,\n",
        "    SUM(post.like_count) / COUNT(post.id) AS avg_likes\n",
        "FROM df_posts post\n",
        "\"\"\"\n",
        "avg_likes = spark.sql(avg_likes_query)\n",
        "avg_likes.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6jMJ3TtHezW",
        "outputId": "5edecf1e-c45d-489c-c14c-029eeedcaa1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------------+--------------+-----------------+\n",
            "|qnt_posts_analyzed|total_comments|     avg_comments|\n",
            "+------------------+--------------+-----------------+\n",
            "|                48|       13124.0|273.4166666666667|\n",
            "+------------------+--------------+-----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 4. AVG Comments per Post\n",
        "avg_comments_query = \"\"\"\n",
        "SELECT\n",
        "    COUNT(post.id) AS qnt_posts_analyzed,\n",
        "    SUM(post.comment_count) AS total_comments,\n",
        "    SUM(post.comment_count) / COUNT(post.id) AS avg_comments\n",
        "FROM df_posts post\n",
        "\"\"\"\n",
        "avg_comments = spark.sql(avg_comments_query)\n",
        "avg_comments.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZtmFQH1IDBW",
        "outputId": "124435b7-9d95-4823-8c60-4eec79dda53b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+-----------------------+------------------------+------------------+\n",
            "|influencer_id|current_followers_count|previous_followers_count|       growth_rate|\n",
            "+-------------+-----------------------+------------------------+------------------+\n",
            "|    482001976|                 822214|                  820374|0.2242879467169852|\n",
            "+-------------+-----------------------+------------------------+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 5. Follower Growth Rate\n",
        "follower_growth_query = \"\"\"\n",
        "SELECT\n",
        "    prof.id AS influencer_id,\n",
        "    MAX(prof.follower_count) AS current_followers_count,\n",
        "    MIN(prof.follower_count) AS previous_followers_count,\n",
        "    ((MAX(prof.follower_count) - MIN(prof.follower_count)) / MIN(prof.follower_count)) * 100 AS growth_rate\n",
        "FROM df_profile prof\n",
        "GROUP BY prof.id\n",
        "\"\"\"\n",
        "follower_growth = spark.sql(follower_growth_query)\n",
        "follower_growth.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZXjJitCJomZ",
        "outputId": "59238fe7-931b-4e00-c393-069304c924ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------------+--------+--------+--------+-------+\n",
            "|qnt_comments_analyzed|positive|negative|humorous|neutral|\n",
            "+---------------------+--------+--------+--------+-------+\n",
            "|                   40|      19|       1|       2|     18|\n",
            "+---------------------+--------+--------+--------+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 6. Sentiment of Comments\n",
        "sentiment_analysis_query = \"\"\"\n",
        "SELECT\n",
        "    COUNT(c.classification) AS qnt_comments_analyzed,\n",
        "    SUM(CASE WHEN c.classification = 'Positive' THEN 1 ELSE 0 END) AS positive,\n",
        "    SUM(CASE WHEN c.classification = 'Negative' THEN 1 ELSE 0 END) AS negative,\n",
        "    SUM(CASE WHEN c.classification = 'Humorous' THEN 1 ELSE 0 END) AS humorous,\n",
        "    SUM(CASE WHEN c.classification NOT IN ('Positive', 'Humorous', 'Negative') THEN 1 ELSE 0 END) AS neutral\n",
        "FROM df_classified_comments c\n",
        "\"\"\"\n",
        "sentiment_analysis = spark.sql(sentiment_analysis_query)\n",
        "sentiment_analysis.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLz6kUTLU8Zl",
        "outputId": "5898f7e0-1b3e-427b-e56c-0cf888a17eec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------------+------------------+\n",
            "|qnt_posts_analyzed|    posts_per_week|\n",
            "+------------------+------------------+\n",
            "|                48|2.0869565217391304|\n",
            "+------------------+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 7. Posting Frequency (Number of Posts per Week)\n",
        "post_frequency_query = \"\"\"\n",
        "SELECT\n",
        "    COUNT(id) AS qnt_posts_analyzed,\n",
        "    COUNT(id) / COUNT(DISTINCT WEEKOFYEAR(to_timestamp(device_timestamp / 1000))) AS posts_per_week\n",
        "FROM df_posts\n",
        "\"\"\"\n",
        "post_frequency = spark.sql(post_frequency_query)\n",
        "post_frequency.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoP2O3SLxT2s",
        "outputId": "2dd3b325-228f-48ab-8de2-411a102e741a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------------+--------------+\n",
            "|      product_type|count_per_type|\n",
            "+------------------+--------------+\n",
            "|             clips|            27|\n",
            "|              feed|            20|\n",
            "|carousel_container|             1|\n",
            "+------------------+--------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 8. Content Variety (Distribution of Media Types)\n",
        "media_distribution_query = \"\"\"\n",
        "SELECT\n",
        "    product_type,\n",
        "    COUNT(*) AS count_per_type\n",
        "FROM df_posts\n",
        "GROUP BY product_type\n",
        "\"\"\"\n",
        "media_distribution = spark.sql(media_distribution_query)\n",
        "media_distribution.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
